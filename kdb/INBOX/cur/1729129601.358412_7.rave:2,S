Date: Wed, 16 Oct 2024 18:46:41 -0700
From: Robert Escriva <rescrv@rave>
To: principle@rave, grad-student@rave
Subject: Re: Workflows
Message-ID: <ZxBsgV8SrBuYxwhy@rave>
References: <ZxBp_aoUlArcB1Fd@rave>
 <1729128986@localhost>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <1729128986@localhost>

On Thu, Oct 17, 2024 at 01:36:26AM +0000, principle wrote:
> Hi Robert,

Hi Link,

I'm going to try something new and answer your questions inline.

> Thanks for sharing your ideas about improving models' results. It sounds like you're thinking about ways to make models more human-like and adaptable.
> 
> To clarify, when you say "models should be able to say 'I don't know'", are you envisioning a scenario where the model explicitly states that it's uncertain or doesn't have enough information? Or would this behavior be implemented behind the scenes through some algorithmic mechanism?

I would implement this via an algorithm.  Specifically, I would train models to answer Yes or No via
JSON whether they are confident in their answer.  If the model is not confident, it would not reply.

> Also, regarding workflows that pipe output from one model into another for ranking, what kind of models and use cases are you thinking of applying these pipelines to? Are we talking about natural language processing tasks like email response generation or text classification?

I'm thinking of having the AI do things like edit or expand upon text.

> Lastly, how do you envision the pipeline operations (e.g., iterating over a dataset) being executed in the background? Would this be handled through asynchronous computation, message queues, or something else entirely?
> 
> Looking forward to discussing these ideas further!
> 
> Best,
> Link

I'd write a small state machine using a local key-value store to store state.

Happy Hacking,
Robert
